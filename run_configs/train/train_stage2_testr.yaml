

init:
  seed: 42


data:
  train:
    name: satext
    hq_img_path: /mnt/dataset1/text_restoration/100K/train
    ann_path: /mnt/dataset1/text_restoration/100K/train/dataset.json
    # hq_prompt_path: /mnt/dataset1/text_restoration/100K/dit4sr/data/train/llava13b_hq_prompt
    hq_prompt_path: 
    null_text_ratio: 0.0 

  val:
    # eval_list: []
    # eval_list: [realtext]
    eval_list: [realtext, satext_lv3, satext_lv2, satext_lv1]

    realtext:
      lq_img_path: /mnt/dataset1/text_restoration/tair_published/real_text/LQ
      hq_img_path: /mnt/dataset1/text_restoration/tair_published/real_text/HQ
      ann_path: /mnt/dataset1/text_restoration/tair_published/real_text/realtext_ann.json
      vlm_captioner: 
      vlm_caption_path: 
      val_num_img: 30

    satext_lv3:
      lq_img_path: /mnt/dataset1/text_restoration/SAMText_test_degradation/lv3
      hq_img_path: /mnt/dataset1/text_restoration/100K/test
      ann_path: /mnt/dataset1/text_restoration/100K/test/dataset.json
      vlm_captioner: 
      vlm_caption_path: 
      val_num_img: 30
  
    satext_lv2:
      lq_img_path: /mnt/dataset1/text_restoration/SAMText_test_degradation/lv2
      hq_img_path: /mnt/dataset1/text_restoration/100K/test
      ann_path: /mnt/dataset1/text_restoration/100K/test/dataset.json
      vlm_captioner: 
      vlm_caption_path: 
      val_num_img: 30

    satext_lv1:
      lq_img_path: /mnt/dataset1/text_restoration/SAMText_test_degradation/lv1
      hq_img_path: /mnt/dataset1/text_restoration/100K/test
      ann_path: /mnt/dataset1/text_restoration/100K/test/dataset.json
      vlm_captioner: 
      vlm_caption_path: 
      val_num_img: 30

    # choose from [gt, pred_tsm, pred_vlm, null]
    text_cond_prompt: pred_tsm
    
    negative_prompt:
    save_prompts: True
    sample_times: 1
    guidance_scale: 1.0
    start_point: lr
    latent_tiled_size: 64
    latent_tiled_overlap: 24
    upscale: 4
    process_size: 512
    num_inference_steps: 40
    align_method: adain
    

model:
  noise_scheduler:
    weighting_scheme: logit_normal
    logit_mean: 0.0
    logit_std: 1.0 
    mode_scale: 1.29
    precondition_outputs: 1

  dit:
    name: dit4sr
    resolution: 512
    load_precomputed_caption: True
    use_gtprompt: True
    text_condition:
      # caption_style: tag
      caption_style: descriptive

  ts_module:
    name: testr 


ckpt:
  init_path:
    vae: preset/models/stable-diffusion-3.5-medium
    noise_scheduler: preset/models/stable-diffusion-3.5-medium
    tokenizer: preset/models/stable-diffusion-3.5-medium
    text_encoder: preset/models/stable-diffusion-3.5-medium
    dit: preset/models/dit4sr/dit4sr_q
    # ts_module:
    ts_module: preset/models/testr/totaltext_testr_R_50_polygon.pth
  resume_path:
    # dit: 
    dit: result_train/fp16_dit4sr_1e-05_lrbranch-attns_ocrlossNone_descriptive_msgDiTfeat24/checkpoint-18000
    ts_module: 


train:
  stage: stage2
  model: ["testr"]
  lr: [1e-4]
  finetune: []
  batch_size: 2
  num_workers: 4
  num_train_epochs: 300
  max_train_steps: 
  mixed_precision: 'fp16'
  lr_scheduler: "constant"
  lr_warmup_steps: 0
  lr_num_cycles: 1
  lr_power: 1.0
  max_grad_norm: 1.0
  set_grads_to_none: False
  gradient_checkpointing: True
  gradient_accumulation_steps: 8
  scale_lr: False
  use_8bit_adam: False
  ocr_loss_weight: 1.0
  # ocr_loss_weight: 0.0
  # ocr_loss_weight: 0.01
  # ocr_loss_weight: 0.1
  # ocr_loss_weight: 0.005
  

val:
  val_every_step: 500


save:
  output_dir: ./result_train/stage2
  checkpointing_steps: 2000


log:
  tracker: 
    report_to: wandb 
    key: e32eed0c2509bf898b850b0065ab62345005fb73
    project_name: cvpr26_tair_extension
    server: 20
    gpu: 5
    # msg: DiTfeat4
    # msg: DiTfeat24_dit4sr_baseline_testr_pretrained
    msg: DiTfeat24_dit4sr_lr1e5_ckpt18k_testr_pretrained
    # msg: DiTfeat24_dit4sr_baseline_testr_scratch
    # msg: DiTfeat24_dit4sr_lr1e5_ckpt18k_testr_scratch
  log_dir: logs
